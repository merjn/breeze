"use strict";

exports.__esModule = true;
exports.createLexer = createLexer;
exports.createTokenOfType = void 0;

var _char = require("@bbob/plugin-helper/lib/char");

var _Token = require("./Token");

var _utils = require("./utils");

/* eslint-disable no-plusplus,no-param-reassign */
// for cases <!-- -->
var EM = '!';
/**
 * Creates a Token entity class
 * @param {String} type
 * @param {String} value
 * @param {Number} r line number
 * @param {Number} cl char number in line
 */

var createToken = function createToken(type, value, r, cl) {
  if (r === void 0) {
    r = 0;
  }

  if (cl === void 0) {
    cl = 0;
  }

  return new _Token.Token(type, value, r, cl);
};
/**
 * @typedef {Object} Lexer
 * @property {Function} tokenize
 * @property {Function} isTokenNested
 */
// [tag attr-name="attr-value"]content[/tag] other content


var STATE_WORD = 0;
var STATE_TAG = 1;
var STATE_ATTR = 2;
var STATE_ATTR_NAME = 3;
var STATE_ATTR_VALUE = 4;
/**
 * @param {String} buffer
 * @param {Object} options
 * @param {Function} options.onToken
 * @param {String} options.openTag
 * @param {String} options.closeTag
 * @param {Boolean} options.enableEscapeTags
 * @return {Lexer}
 */

function createLexer(buffer, options) {
  if (options === void 0) {
    options = {};
  }

  var row = 0;
  var col = 0;
  var tokenIndex = -1;
  var mode = 0;
  var tokens = new Array(Math.floor(buffer.length));
  var openTag = options.openTag || _char.OPEN_BRAKET;
  var closeTag = options.closeTag || _char.CLOSE_BRAKET;
  var escapeTags = options.enableEscapeTags;
  var RESERVED_CHARS = [closeTag, openTag, _char.QUOTEMARK, _char.BACKSLASH, _char.SPACE, _char.TAB, _char.EQ, _char.N, EM];
  var NOT_CHAR_TOKENS = [// ...(options.enableEscapeTags ? [BACKSLASH] : []),
  openTag, _char.SPACE, _char.TAB, _char.N];
  var WHITESPACES = [_char.SPACE, _char.TAB];
  var SPECIAL_CHARS = [_char.EQ, _char.SPACE, _char.TAB];

  var isCharReserved = char => RESERVED_CHARS.indexOf(char) >= 0;

  var isNewLine = char => char === _char.N;

  var isWhiteSpace = char => WHITESPACES.indexOf(char) >= 0;

  var isCharToken = char => NOT_CHAR_TOKENS.indexOf(char) === -1;

  var isSpecialChar = char => SPECIAL_CHARS.indexOf(char) >= 0;

  var isEscapableChar = char => char === openTag || char === closeTag || char === _char.BACKSLASH;

  var isEscapeChar = char => char === _char.BACKSLASH;

  var bufferGrabber = (0, _utils.createCharGrabber)(buffer, {
    onSkip: () => {
      col++;
    }
  });
  /**
   * Emits newly created token to subscriber
   * @param token
   */

  var emitToken = token => {
    if (options.onToken) {
      options.onToken(token);
    }

    tokenIndex += 1;
    tokens[tokenIndex] = token;
  };

  var switchMode = newMode => {
    mode = newMode;
  };

  var processWord = () => {
    var currChar = bufferGrabber.getCurr();
    var nextChar = bufferGrabber.getNext();

    if (currChar === openTag && bufferGrabber.includes(closeTag)) {
      return switchMode(STATE_TAG);
    }

    if (isNewLine(currChar)) {
      bufferGrabber.skip();
      col = 0;
      row++;
      return emitToken(createToken(_Token.TYPE_NEW_LINE, currChar, row, col));
    }

    if (isWhiteSpace(currChar)) {
      return emitToken(createToken(_Token.TYPE_SPACE, bufferGrabber.grabWhile(isWhiteSpace), row, col));
    }

    if (escapeTags) {
      if (isEscapeChar(currChar) && !isEscapableChar(nextChar)) {
        bufferGrabber.skip();
        return emitToken(createToken(_Token.TYPE_WORD, currChar, row, col));
      }

      var _str = bufferGrabber.grabWhile(char => isCharToken(char) && !isEscapeChar(char));

      return emitToken(createToken(_Token.TYPE_WORD, _str, row, col));
    }

    var str = bufferGrabber.grabWhile(char => isCharToken(char));
    return emitToken(createToken(_Token.TYPE_WORD, str, row, col));
  };

  var processTag = () => {
    var currChar = bufferGrabber.getCurr();
    var nextChar = bufferGrabber.getNext();

    if (currChar === closeTag) {
      bufferGrabber.skip(); // skip closeTag

      switchMode(STATE_WORD);
      return emitToken(createToken(_Token.TYPE_WORD, currChar, row, col));
    }

    if (currChar === openTag) {
      bufferGrabber.skip(); // skip openTag
      // detect case where we have '[My word [tag][/tag]' or we have '[My last line word'

      var str = bufferGrabber.grabWhile(val => val !== closeTag);
      var hasInvalidChars = str.length === 0 || str.indexOf(openTag) >= 0;

      if (isCharReserved(nextChar) || hasInvalidChars || bufferGrabber.isLast()) {
        return emitToken(createToken(_Token.TYPE_WORD, currChar, row, col));
      }

      bufferGrabber.skip(); // skip closeTag
      // [myTag   ]

      var isNoAttrsInTag = str.indexOf(_char.EQ) === -1; // [/myTag]

      var isClosingTag = str[0] === _char.SLASH;

      if (isNoAttrsInTag || isClosingTag) {
        return emitToken(createToken(_Token.TYPE_TAG, str, row, col));
      }
    }

    return switchMode(STATE_WORD);
  };

  var processAttrName = () => {};

  var processAttrValue = () => {};

  var modeMap = {
    [STATE_WORD]: processWord,
    [STATE_TAG]: processTag,
    [STATE_ATTR_NAME]: processAttrName,
    [STATE_ATTR_VALUE]: processAttrValue
  };

  var tokenize = () => {
    while (bufferGrabber.hasNext()) {
      modeMap[mode](bufferGrabber);
    }

    tokens.length = tokenIndex + 1;
    return tokens;
  };

  var isTokenNested = token => {
    var value = openTag + _char.SLASH + token.getValue(); // potential bottleneck

    return buffer.indexOf(value) > -1;
  };

  return {
    tokenize,
    isTokenNested
  };
}

var createTokenOfType = createToken;
exports.createTokenOfType = createTokenOfType;